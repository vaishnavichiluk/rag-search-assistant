ğŸ“˜ RAG-Based Intelligent Search Assistant

A Lightweight, Fast, and Fully Local Retrieval-Augmented Generation System

ğŸŒŸ Overview

The RAG-Based Intelligent Search Assistant is a smart document-question answering system that allows users to ask natural language questions about any PDF and get accurate, context-grounded answers.

Instead of relying on cloud APIs or expensive models, the system uses:

FAISS for fast local vector search

Sentence-Transformer embeddings for semantic understanding

FLAN-T5 (HuggingFace) as a free, lightweight LLM

A clean Streamlit UI for seamless interaction

This creates a powerful mini â€œChatGPT for your PDFsâ€â€”running completely on your local machine.

ğŸ¯ Key Features
ğŸ” Ask questions about any PDF

The system retrieves the most relevant text chunks from your documents and produces a grounded, context-aware answer.

âš¡ Local & Free â€” No API Keys Required

Runs entirely on your system using HuggingFace models.
No OpenAI keys, billing issues, or rate limits.

ğŸ§  RAG Architecture

Implements real Retrieval-Augmented Generation:

Document â†’ Text â†’ Chunks â†’ Embeddings â†’ FAISS Index â†’ Retrieval â†’ LLM Answer

ğŸ–¥ï¸ Interactive Streamlit UI

Beautiful interface where users can type questions and view answers instantly.

ğŸ“„ PDF Support

Drop multiple PDFs into the data/ folder â€” the system will automatically process them.

ğŸ—ï¸ Architecture Diagram
             â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
             â”‚      PDF Files       â”‚
             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
                        â–¼
             â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
             â”‚   Text Extraction    â”‚
             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
                        â–¼
             â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
             â”‚   Chunking (RAG)     â”‚
             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
                        â–¼
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚ Sentence Embeddings      â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
                        â–¼
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚   FAISS Index      â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â–¼
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚ Relevant Chunk Retrieval     â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
                    â–¼
       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚ FLAN-T5 LLM (HF Pipeline)   â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â–¼
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚   Final Answer    â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ğŸš€ Getting Started
ğŸ“¦ 1. Clone the repository
git clone <your-repo-url>
cd rag-search-assistant

ğŸ“ 2. Install dependencies
pip install streamlit langchain langchain-community langchain-core \
            sentence-transformers faiss-cpu transformers accelerate \
            sentencepiece pypdf

ğŸ“ 3. Add your PDFs

Place all your PDF files inside:

./data/

ğŸ§  4. Build the vector store
python app.py


This will create a vector_index/ folder automatically.

ğŸ–¥ï¸ 5. Run the Streamlit app
python -m streamlit run ui.py


Your local RAG assistant will open in the browser.

ğŸ§ª Example Query

Question:
â€œExplain Generative AI based on the document.â€

Answer:
(Generated using retrieved PDF content.)
A generative model is a type of AI system capable of producing new data such as text, images, audioâ€¦

ğŸ› ï¸ Tech Stack
Component	Technology
UI	Streamlit
LLM	HuggingFace Flan-T5
Embeddings	Sentence Transformers
Vector Search	FAISS
Framework	LangChain
Language	Python 3.12
ğŸ“Œ What Makes This Project Special?
âœ” Fully Local, Privacy-Friendly

No data leaves your machine.

âœ” Lightweight & Works on Normal Laptops

Flan-T5 is small, fast, and reliable.

âœ” Clean Architecture

Shows real-world RAG implementation used in modern AI companies.

âœ” Portfolio-Ready

Perfect addition for AI/ML internships and professional interviews.

ğŸ“š Use Cases

Summarize long documents

Question answering over PDFs

AI-driven knowledge search

Study assistant

AI-powered documentation explorer
